# Academic Analytics Engine

A data analytics system designed to turn raw academic results into explainable insights for students, teachers, and administrators.

## ğŸš€ Overview

This project implements a **Data â†’ Metrics â†’ Insights â†’ NLP** pipeline to analyze student performance trends, improvement/decline, and subject correlations. Unlike black-box ML models, this engine prioritizes **explainability** and **rule-based logic** to provide transparent actionable feedback.

### Key Features
- **Trend Analysis**: Tracks performance over time (Semesters/Years).
- **Insight Detection**: Automatically identifies significant improvements or declines.
- **Natural Language Summaries**: Converts data insights into human-readable text.
- **Subject Correlations**: Heatmaps showing relationships between subject performances.
- **API First**: Fully decoupled FastAPI backend serving ready-to-consume insights.

## ğŸ— Architecture

The system is built on a 4-layer architecture:

1.  **Data Layer**: Ingests normalized CSV data.
2.  **Metrics Layer**: Computes objective statistics (averages, deltas, correlations).
3.  **Insight Layer**: Applies rules to metrics to detect patterns.
4.  **NLP Layer**: Generates English descriptions from structured insights.

## ğŸ›  Tech Stack

- **Core Engine**: Python (Pandas, NumPy)
- **API**: FastAPI (Uvicorn)
- **Frontend**: Next.js (React, Tailwind CSS, Recharts)

## ğŸ“¦ Installation

1.  Clone the repository:
    ```bash
    git clone https://github.com/michaelnkema1/results-analytics-engine.git
    cd results-analytics-engine
    ```

2.  Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```
    *(Note: For the frontend, run `npm install` inside `src/web` if starting manually).*

## ğŸƒ Usage

### 1. Unified Start (Recommended)
The easiest way to start both the backend and frontend is using the helper script:

```bash
./start.sh
```
- **Backend API**: `http://localhost:8000`
- **Web Dashboard**: `http://localhost:3000`

### 2. Manual Startup
If you prefer running them separately:

**Backend:**
```bash
./run_backend.sh
```

**Frontend:**
```bash
cd src/web
npm run dev
```

### 3. API Endpoints
| Method | Endpoint | Description |
| :--- | :--- | :--- |
| `POST` | `/api/v1/datasets/upload` | Upload raw CSV dataset |
| `POST` | `/api/v1/datasets/{id}/process` | Normalize and ingest dataset |
| `GET` | `/api/v1/students` | List all students |
| `GET` | `/api/v1/students/{id}/summary` | Individual student performance & automation insights |
| `GET` | `/api/v1/cohort/trends` | Year-over-year subject performance trends |
| `GET` | `/api/v1/cohort/correlations` | Subject correlation matrix |

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ start.sh                # Main entry point (Backend + Frontend)
â”œâ”€â”€ run_backend.sh          # Helper script for backend only
â”œâ”€â”€ results.csv             # Sample dataset
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                # FastAPI Application
â”‚   â”‚   â””â”€â”€ main.py         # API Routes & Lifespan Logic
â”‚   â”œâ”€â”€ engine/             # Core Analytics Logic
â”‚   â”‚   â”œâ”€â”€ ingest.py       # Data Ingestion & Normalization
â”‚   â”‚   â”œâ”€â”€ metrics.py      # Statistical computations
â”‚   â”‚   â”œâ”€â”€ insights.py     # Rule-based pattern detection
â”‚   â”‚   â””â”€â”€ nlp.py          # Text generation
â”‚   â””â”€â”€ web/                # Next.js Frontend
â”‚       â”œâ”€â”€ app/            # App Router Pages
â”‚       â”œâ”€â”€ components/     # Shared Components
â”‚       â””â”€â”€ lib/            # Utilities
```

## ğŸ¤ Contributing

This project is in active development.
- **Phase 1 & 2**: Core Engine & API (Completed)
- **Phase 3**: Web Dashboard (Completed)
- **Phase 4**: Machine Learning / Predictive Models (Planned)
